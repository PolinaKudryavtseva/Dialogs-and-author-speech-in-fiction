{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Копия блокнота \"курсовая.ipynb\"",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "QvrzPsSZ7zM3"
      },
      "source": [
        "import re\n",
        "import os\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import nltk\n",
        "nltk.download('punkt')\n",
        "from nltk.tokenize import word_tokenize\n",
        "from collections import Counter\n",
        "import collections\n",
        "from tqdm.auto import tqdm\n",
        "from pymorphy2 import MorphAnalyzer\n",
        "morph = MorphAnalyzer()\n",
        "from statistics import mean\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import json\n",
        "from bs4 import BeautifulSoup"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MH1k2i2w8C_0"
      },
      "source": [
        "#функция отделяет авторскую речь от диалогов в книгах каждого автора \n",
        "#для каждого автора создается два файла:\n",
        "#1. с диалогами из всех его книг dialog_[имя автора].txt\n",
        "#2. с авторской речью из всех его книг author_[имя автора].txt\n",
        "\n",
        "def separate_dialogs_from_author_speech(dirname, author):\n",
        "\n",
        "    dialogs = []\n",
        "    author_speeches = []\n",
        "\n",
        "    dir = os.listdir(dirname)\n",
        "\n",
        "    for i in dir:\n",
        "        if i.endswith('.txt'):\n",
        "            filename = dirname + '/' + i\n",
        "\n",
        "            with open(filename, 'r', encoding = 'utf-8') as t:\n",
        "                text = t.read()\n",
        "                for string in text.split('\\n'):\n",
        "                    if string is not '':\n",
        "                        quot_marked = re.findall(': [«|\"].*[»|\"]', string)\n",
        "                        if string.startswith('–') or string.startswith('-') or string.startswith('—'):\n",
        "                            dashes = re.findall('[–|\\-|—]', string)\n",
        "                            if len(dashes) == 1:\n",
        "                                oral_speech = string\n",
        "                                dialogs.append(oral_speech)\n",
        "                                dialogs.append('\\n')\n",
        "                            elif len(dashes) == 2:\n",
        "                                paragraph = re.search('([–|\\-|—].*[,|!|?|\\.\\.\\.]) [–|\\-|—](.*)', string)\n",
        "                                if paragraph is not None:\n",
        "                                    oral_speech = paragraph.group(1)\n",
        "                                    author_speech = paragraph.group(2)\n",
        "                                    dialogs.append(oral_speech)\n",
        "                                    dialogs.append('\\n')\n",
        "                                    author_speeches.append(author_speech)\n",
        "                                    author_speeches.append('\\n')\n",
        "                                else:\n",
        "                                    oral_speech = string\n",
        "                                    dialogs.append(oral_speech)\n",
        "                                    dialogs.append('\\n')\n",
        "                            elif len(dashes) == 3:\n",
        "                                paragraph = re.search('([–|\\-|—].*[,|!|?|\\.\\.\\.]) [–|\\-|—](.*)\\. [–|\\-|—](.*)', string)\n",
        "                                if paragraph is not None:\n",
        "                                    oral_speech = paragraph.group(1) + paragraph.group(3)\n",
        "                                    author_speech = paragraph.group(2)\n",
        "                                    dialogs.append(oral_speech)\n",
        "                                    dialogs.append('\\n')\n",
        "                                    author_speeches.append(author_speech)\n",
        "                                    author_speeches.append('\\n')\n",
        "                                else:\n",
        "                                    paragraph = re.search('([–|\\-|—].*[,|!|?|\\.\\.\\.]) [–|\\-|—](.*)', string)\n",
        "                                    if paragraph is not None:\n",
        "                                        oral_speech = paragraph.group(1)\n",
        "                                        author_speech = paragraph.group(2)\n",
        "                                        dialogs.append(oral_speech)\n",
        "                                        dialogs.append('\\n')\n",
        "                                        author_speeches.append(author_speech)\n",
        "                                        author_speeches.append('\\n')\n",
        "                                    else:\n",
        "                                        paragraph = re.search('([–|\\-|—].*[,|!|?|\\.\\.\\.]) [–|\\-|—](.*)\\. [–|\\-|—](.*), [–|\\-|—] (.*)', string)\n",
        "                                        if paragraph is not None:\n",
        "                                            oral_speech = paragraph.group(1) + paragraph.group(3)\n",
        "                                            author_speech = paragraph.group(2)\n",
        "                                            dialogs.append(oral_speech)\n",
        "                                            dialogs.append('\\n')\n",
        "                                            author_speeches.append(author_speech)\n",
        "                                            author_speeches.append('\\n')\n",
        "                            else:\n",
        "                                paragraph = re.search('([–|\\-|—].*[,|!|?|\\.\\.\\.]) [–|\\-|—](.*)\\. [–|\\-|—](.*)', string)\n",
        "                                if paragraph is not None:\n",
        "                                    oral_speech = paragraph.group(1) + paragraph.group(3)\n",
        "                                    author_speech = paragraph.group(2)\n",
        "                                    dialogs.append(oral_speech)\n",
        "                                    dialogs.append('\\n')\n",
        "                                    author_speeches.append(author_speech)\n",
        "                                    author_speeches.append('\\n')\n",
        "                        elif len(quot_marked) is not 0:\n",
        "                            for frase in quot_marked:\n",
        "                                oral_speech = frase.replace(':', '').replace('«', '').replace('»', '')\n",
        "                                string = string.replace(frase, '')\n",
        "                                author_speech = string\n",
        "                                dialogs.append(oral_speech)\n",
        "                                dialogs.append('\\n')\n",
        "                                author_speeches.append(author_speech)\n",
        "                                author_speeches.append('\\n')\n",
        "                        elif string.startswith('«') or string.startswith('\\\"'):\n",
        "                            quoted = re.search('[\\\"|«].*[\\\"|»]', string)\n",
        "                            if quoted is not None:\n",
        "                                quoted_dashes = re.findall(' [–|\\-|—] ', quoted.group())\n",
        "                                if len(quoted_dashes) == 0:\n",
        "                                    oral_speech = string\n",
        "                                    dialogs.append(oral_speech)\n",
        "                                    dialogs.append('\\n')\n",
        "                                else:\n",
        "                                    paragraph = re.search('([\\\"|«].*[,|!|?|\\.\\.\\.]) [–|\\-|—](.*\\.)(.*[\\\"|»])', quoted.group())\n",
        "                                    if paragraph is not None:\n",
        "                                        oral_speech = paragraph.group(1) + paragraph.group(3)\n",
        "                                        author_speech = paragraph.group(2)\n",
        "                                        dialogs.append(oral_speech)\n",
        "                                        dialogs.append('\\n')\n",
        "                                        author_speeches.append(author_speech)\n",
        "                                        author_speeches.append('\\n')\n",
        "                        else:\n",
        "                            author_speech = string\n",
        "                            author_speeches.append(author_speech)\n",
        "                            author_speeches.append('\\n')\n",
        "\n",
        "    dialog_file = 'dialog_' + author + '.txt'\n",
        "    author_file = 'author_' + author + '.txt'\n",
        "        \n",
        "    with open (dialog_file, 'w', encoding = 'utf-8') as f:\n",
        "        for i in dialogs:\n",
        "            f.write(i)\n",
        "    with open (author_file, 'w', encoding = 'utf-8') as f:\n",
        "        for i in author_speeches:\n",
        "            f.write(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KRBGQMTAj8m"
      },
      "source": [
        "#функция чистит файл от аннотаций, имен авторов, оглавления и др.\n",
        "def file_cleaning(author, dirname):\n",
        "\n",
        "    dir = os.listdir(dirname)\n",
        "\n",
        "    for i in dir:\n",
        "        if i.endswith('.txt'):\n",
        "            print(i)\n",
        "            filename = dirname + '/' + i\n",
        "\n",
        "            with open(filename, 'r', encoding = 'utf-8') as t:\n",
        "                text = t.read()\n",
        "\n",
        "                text = re.sub('ГЛАВА \\d*', '', text)\n",
        "                text = re.sub('Глава \\d*', '', text)\n",
        "                text = re.sub('^Глава \\w*', '', text)\n",
        "                text = re.sub('Annotation\\n.*\\n', '', text)\n",
        "                text = text.replace('*', '')\n",
        "                text = text.replace(author, '')\n",
        "                text = text.replace('\\n\\n', '')\n",
        "                text = re.sub('\\n\\d*\\n', '', text)\n",
        "                text = re.sub('\\* \\* \\*\\n*notes(\\n*.*)*', '', text)\n",
        "                text = re.sub('notes\\d*', '', text)\n",
        "                text = re.sub('^\t\t\t', '', text)\n",
        "                text = text.replace('ФРИДРИХ НЕЗНАНСКИЙ', '')\n",
        "                text = text.replace('Фридрих Незнанский', '')\n",
        "\n",
        "            newfilename = filename.replace('.txt', '_cleaned.txt')\n",
        "\n",
        "            with open(newfilename, 'w', encoding = 'utf-8') as f:\n",
        "                f.write(text)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5CcS6UKH8f-H"
      },
      "source": [
        "# фукнция делать датафрейм с разными показателями устной речи и собирает словарь с формой слова и частью речи\n",
        "def making_df(dirname):\n",
        "\n",
        "    columns = ['показатели', 'прямая речь', 'авторская речь', 'автроская речь от первого лица']\n",
        "    #columns = ['показатели', 'автроская речь от первого лица']\n",
        "    listparameters = []\n",
        "    listdialogs = []\n",
        "    listauthor_speech = []\n",
        "    listfirstface = []\n",
        "\n",
        "    author_lemmas = []\n",
        "    dialog_lemmas = []\n",
        "    firstface_lemmas = []\n",
        "    author_words = []\n",
        "    dialog_words = []\n",
        "    firstface_words = []\n",
        "    author_forms = []\n",
        "    dialog_forms = []\n",
        "    firstface_forms = []\n",
        "\n",
        "    dir = os.listdir(dirname)\n",
        " \n",
        "    for i in tqdm(dir):\n",
        "        if i.endswith('.txt'):\n",
        "            print(i)\n",
        "            filename = dirname + '/' + i\n",
        "            if i.startswith('author'):\n",
        "                listfordf = listauthor_speech\n",
        "                lemmas = author_lemmas\n",
        "                textwords = author_words\n",
        "                forms_from_text = author_forms\n",
        "            if i.startswith('dialog'):\n",
        "                listfordf = listdialogs\n",
        "                lemmas = dialog_lemmas\n",
        "                textwords = dialog_words\n",
        "                forms_from_text = dialog_forms\n",
        "            if i.startswith('firstface'):\n",
        "                listfordf = listfirstface\n",
        "                lemmas = firstface_lemmas\n",
        "                textwords = firstface_words\n",
        "                forms_from_text = firstface_forms\n",
        "\n",
        "            with open(filename, 'r', encoding = 'utf-8') as t:\n",
        "                text = t.read()\n",
        "               \n",
        "                split_regex = re.compile(r'[\\.|!|?|…]')\n",
        "                sentences = []\n",
        "                replicas = [t.strip() for t in split_regex.split(text)]\n",
        "                for replica in replicas:\n",
        "                    if replica != '':\n",
        "                        sentences.append(replica)\n",
        "                \n",
        "                exclamations = len(re.findall('!', text))\n",
        "                listparameters.append('Восклицательные предложения')\n",
        "                listfordf.append(exclamations)\n",
        "                listparameters.append('Процент восклицательных предложений')\n",
        "                listfordf.append(round(exclamations*100/len(sentences)))\n",
        "\n",
        "                questions = len(re.findall('\\?', text))\n",
        "                listparameters.append('Вопросительные предложения')\n",
        "                listfordf.append(questions)\n",
        "                listparameters.append('Процент вопросительных предложений')\n",
        "                listfordf.append(round(questions*100/len(sentences)))\n",
        "\n",
        "                len_replicas = []\n",
        "                for replica in replicas:\n",
        "                    if replica != '':\n",
        "                        tokens = word_tokenize(replica.lower())\n",
        "                        words = [w for w in tokens if w.isalpha()]\n",
        "                        textwords.extend(words)\n",
        "                        len_replicas.append(len(words))\n",
        "                listparameters.append('Средняя длина предложения')\n",
        "                listfordf.append(mean(len_replicas))\n",
        "\n",
        "                word_counter = Counter(textwords)\n",
        "                all_words = len(textwords)\n",
        "                listfordf.append(all_words)\n",
        "                listparameters.append('Всего слов')\n",
        "\n",
        "                df_words = ['ну', 'а', \n",
        "                            'вот', 'значит',\n",
        "                            'да', 'нет',\n",
        "                            'здесь', 'сегодня', 'сейчас',\n",
        "                            'тут', 'там', 'тогда', 'такой', 'так',\n",
        "                            'я']\n",
        "\n",
        "                for word in df_words:\n",
        "                    count = word_counter[word]\n",
        "                    listfordf.append(count)\n",
        "                    procent = round(count*100/all_words)\n",
        "                    listfordf.append(procent)\n",
        "\n",
        "                    listparameters.append(word)\n",
        "                    listparameters.append('Процент вхождений \\\"{}\\\"'.format(word))\n",
        "\n",
        "                for i in textwords:\n",
        "                    analise = morph.parse(i)\n",
        "                    lemmas.append(analise)\n",
        "                        \n",
        "                forms_from_text = []\n",
        "                for lemma in lemmas:\n",
        "                    one = lemma[0]\n",
        "                    form = [one.normal_form, one.tag.POS]\n",
        "                    forms_from_text.append(form)\n",
        "\n",
        "\n",
        "    #df = pd.DataFrame(zip(listparameters, listfirstface), columns=columns)\n",
        "    df = pd.DataFrame(zip(listparameters, listdialogs, listauthor_speech, listfirstface), columns=columns)\n",
        "    # df, firstface_lemmas, firstface_words\n",
        "    \n",
        "    return df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0w6RCKV-ALuT"
      },
      "source": [
        "def getting_forms(name_of_forms, lemmas):\n",
        "    name_of_forms = []\n",
        "    for lemma in tqdm(lemmas):\n",
        "        one = lemma[0]\n",
        "        form = [one.normal_form, one.tag.POS]\n",
        "        name_of_forms.append(form)\n",
        "    return name_of_forms"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LZFleKPv4snr"
      },
      "source": [
        "# функция достает топ-20 слов каждой части речи\n",
        "def top_of_pos(forms):\n",
        "\n",
        "    verb_counter = collections.Counter()\n",
        "    noun_counter = collections.Counter()\n",
        "    adj_counter = collections.Counter()\n",
        "    npro_counter = collections.Counter() \n",
        "    intj_counter = collections.Counter()\n",
        "                    \n",
        "\n",
        "    for i in tqdm(forms):\n",
        "        if i[1] == 'VERB':\n",
        "            verb_counter[i[0]] += 1\n",
        "        elif i[1] == 'NOUN':\n",
        "            noun_counter[i[0]] += 1\n",
        "        elif i[1] == 'ADJF' or i[1] == 'ADJS':\n",
        "            adj_counter[i[0]] += 1\n",
        "        elif i[1] == 'NPRO':\n",
        "            npro_counter[i[0]] += 1\n",
        "        elif i[1] == 'INTJ':\n",
        "            intj_counter[i[0]] += 1\n",
        "                                \n",
        "    verb_top = verb_counter.most_common(20)\n",
        "    noun_top = noun_counter.most_common(20)\n",
        "    adj_top = adj_counter.most_common(20)\n",
        "    npro_top = npro_counter.most_common(20)\n",
        "    intj_top = intj_counter.most_common(20)\n",
        "\n",
        "    return verb_top, noun_top, adj_top, npro_top, intj_top"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fcvyMh6y_4Wt"
      },
      "source": [
        "#функция сообщает о количестве междометий\n",
        "def intj(forms):\n",
        "    intj_counter = collections.Counter()\n",
        "    for i in forms:\n",
        "        if i[1] == 'INTJ':\n",
        "            intj_counter[i[0]] += 1\n",
        "    return sum(intj_counter.values())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghLegnTz51uu"
      },
      "source": [
        "# функция делает датафрейм, чтобы нарисовать график\n",
        "def df_for_graphs_procents(forms, csv_name, count_words):\n",
        "\n",
        "    counter_of_forms = collections.Counter()\n",
        "    allf = 0\n",
        "    for i in forms:\n",
        "        allf = allf + 1\n",
        "        form = i[1]\n",
        "        counter_of_forms[form] += 1\n",
        "\n",
        "    procents = []\n",
        "    for i in counter_of_forms.values():\n",
        "        procents.append(i*100/count_words)\n",
        "\n",
        "    df = pd.DataFrame(procents, counter_of_forms.keys())\n",
        "    df.to_csv(csv_name)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBL5etckhF9Z"
      },
      "source": [
        "# функция составляет график с частотностями частей речи, на вход датафрейм с столбцами pos и freq\n",
        "def df_sort(df):\n",
        "    return df.sort_values(by=['pos'])\n",
        "def graphic(df, name):\n",
        "\n",
        "    pos = df['pos']\n",
        "\n",
        "    frequency_of_pos = df['freq']\n",
        "\n",
        "    plt.bar(pos, frequency_of_pos, color=['#E24A33', '#348ABD', '#988ED5', '#777777', '#FBC15E', '#8EBA42',\n",
        "                                        '#FFB5B8', '#003FFF', '#03ED3A', '#E8000B', '#8A2BE2', '#FFC400',\n",
        "                                        '#00D7FF', '#348ABD', '#A60628', '#7A68A6', '#467821'])\n",
        "    plt.xticks(rotation='vertical')\n",
        "    plt.title(name)\n",
        "    plt.ylabel('Частотность')\n",
        "    plt.xlabel('Части речи')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLtOcziuewrP"
      },
      "source": [
        "# функция создает датафрейм с маркерами устной речи и их количеством в тексте\n",
        "def new_df(dirname):\n",
        "\n",
        "    speech_verbs = ['говорить', 'сказать', 'называть', 'назвать', 'рассказывать',\n",
        "                    'рассказать', 'благодарить', 'отвечать', 'ответить', 'предложить',\n",
        "                    'предлагать', 'уверять', 'уверить', 'требовать', 'объявить',\n",
        "                    'просить', 'спрашивать', 'спросить', 'спорить', 'повторить',\n",
        "                    'повторять', 'обещать', 'возразить', 'признаться', 'признаваться',\n",
        "                    'жаловаться', 'пожаловаться', 'поблагодарить', 'обещать', 'советовать'] #30\n",
        "    mental_verbs = ['знать', 'думать', 'понимать', 'понять', 'помнить',\n",
        "                    'решить', 'подумать', 'мечтать', 'решать', 'забыть',\n",
        "                    'вспомнить', 'верить', 'надеяться', 'придумать', 'поверить',\n",
        "                    'задуматься', 'судить', 'сомневаться', 'напоминать', 'предполагать',\n",
        "                    'узнавать', 'узнать', 'определиться', 'определяться', 'полагать',\n",
        "                    'забывать', 'напомнить', 'предусмотреть', 'вздумать', 'выяснить'] #30\n",
        "\n",
        "\n",
        "    columns = ['показатели', 'прямая речь', 'авторская речь']\n",
        "    #columns = ['показатели', 'прямая речь']\n",
        "    listparameters = []\n",
        "    listdialogs = []\n",
        "    listauthor_speech = []\n",
        "    listfirstface = []\n",
        "\n",
        "    author_lemmas = []\n",
        "    dialog_lemmas = []\n",
        "    firstface_lemmas = []\n",
        "    author_words = []\n",
        "    dialog_words = []\n",
        "    firstface_words = []\n",
        "    author_forms = []\n",
        "    dialog_forms = []\n",
        "    firstface_forms = []\n",
        "\n",
        "    dir = os.listdir(dirname)\n",
        " \n",
        "    for i in tqdm(dir):\n",
        "        if i.endswith('.txt'):\n",
        "            print(i)\n",
        "            filename = dirname + '/' + i\n",
        "            if i.startswith('author'):\n",
        "                listfordf = listauthor_speech\n",
        "                lemmas = author_lemmas\n",
        "                textwords = author_words\n",
        "                forms_from_text = author_forms\n",
        "            if i.startswith('dialog'):\n",
        "                listfordf = listdialogs\n",
        "                lemmas = dialog_lemmas\n",
        "                textwords = dialog_words\n",
        "                forms_from_text = dialog_forms\n",
        "            if i.startswith('firstface'):\n",
        "                listfordf = listfirstface\n",
        "                lemmas = firstface_lemmas\n",
        "                textwords = firstface_words\n",
        "                forms_from_text = firstface_forms\n",
        "            \n",
        "            first_person = 0\n",
        "            impr = 0\n",
        "            speech_verbs_first_person = 0\n",
        "            mental_verbs_first_person = 0\n",
        "            speech_mental_verbs_second_person = 0\n",
        "\n",
        "            with open(filename, 'r', encoding = 'utf-8') as t:\n",
        "                text = t.read()\n",
        "\n",
        "                split_regex = re.compile(r'[\\.|!|?|…]')\n",
        "                sentences = []\n",
        "                replicas = [t.strip() for t in split_regex.split(text)]\n",
        "                for replica in replicas:\n",
        "                    if replica != '':\n",
        "                        sentences.append(replica)\n",
        "\n",
        "                for replica in replicas:\n",
        "                    if replica != '':\n",
        "                        tokens = word_tokenize(replica.lower())\n",
        "                        words = [w for w in tokens if w.isalpha()]\n",
        "                        textwords.extend(words)\n",
        "\n",
        "                word_counter = Counter(textwords)\n",
        "                all_words = len(textwords)\n",
        "                listfordf.append(all_words)\n",
        "                listparameters.append('Всего слов')\n",
        "\n",
        "                df_words = ['ну', 'а', \n",
        "                            'вот', 'значит',\n",
        "                            'да', 'нет',\n",
        "                            'здесь', 'сегодня', 'сейчас',\n",
        "                            'тут', 'там', 'тогда', 'такой', 'так',\n",
        "                            'я', 'очень',\n",
        "                            'ты', 'вы']\n",
        "\n",
        "            for word in df_words:\n",
        "                count = word_counter[word]\n",
        "                listfordf.append(count)\n",
        "                procent = round(count/all_words*1000000)\n",
        "                listfordf.append(procent)\n",
        "                listparameters.append(word)\n",
        "                listparameters.append('Процент вхождений \\\"{}\\\"'.format(word))\n",
        "\n",
        "            for i in textwords:\n",
        "                analise = morph.parse(i)\n",
        "                lemmas.append(analise)\n",
        "\n",
        "            for lemma in lemmas:\n",
        "                if lemma[0].tag.POS == 'VERB':\n",
        "                    if re.search('1per', str(lemma[0].tag)):\n",
        "                        first_person += 1\n",
        "                        for verb in speech_verbs:\n",
        "                            regexp = '^' + verb + '$'\n",
        "                            if re.search(regexp, lemma[0].normal_form) is not None:\n",
        "                                speech_verbs_first_person += 1\n",
        "                        for verb in mental_verbs:\n",
        "                            regexp = '^' + verb + '$'\n",
        "                            if re.search(regexp, lemma[0].normal_form) is not None:\n",
        "                                mental_verbs_first_person += 1\n",
        "                    if re.search('2per', str(lemma[0].tag)):\n",
        "                        for verb in speech_verbs:\n",
        "                            regexp = '^' + verb + '$'\n",
        "                            if re.search(regexp, lemma[0].normal_form) is not None:\n",
        "                                speech_mental_verbs_second_person += 1\n",
        "                        for verb in mental_verbs:\n",
        "                            regexp = '^' + verb + '$'\n",
        "                            if re.search(regexp, lemma[0].normal_form) is not None:\n",
        "                                speech_mental_verbs_second_person += 1\n",
        "                    if re.search('impr', str(lemma[0].tag)):\n",
        "                        impr += 1\n",
        "                        \n",
        "\n",
        "            listfordf.append(first_person)\n",
        "            procent = round(first_person/all_words*1000000)\n",
        "            listfordf.append(procent)\n",
        "            listparameters.append('Глаголы 1 лица')\n",
        "            listparameters.append('Процент вхождений глаголов 1 лица')\n",
        "\n",
        "            listfordf.append(impr)\n",
        "            procent = round(impr/all_words*1000000)\n",
        "            listfordf.append(procent)\n",
        "            listparameters.append('Глаголы impr')\n",
        "            listparameters.append('Процент вхождений глаголов impr')\n",
        "\n",
        "            listfordf.append(speech_verbs_first_person)\n",
        "            procent = round(speech_verbs_first_person/all_words*1000000)\n",
        "            listfordf.append(procent)\n",
        "            listparameters.append('Глаголы говорения в 1 лице')\n",
        "            listparameters.append('Процент вхождений глаголов говорения в 1 лице')\n",
        "\n",
        "            listfordf.append(mental_verbs_first_person)\n",
        "            procent = round(mental_verbs_first_person/all_words*1000000)\n",
        "            listfordf.append(procent)\n",
        "            listparameters.append('Глаголы ментальной сферы в 1 лице')\n",
        "            listparameters.append('Процент вхождений глаголов ментальной сферы в 1 лице')\n",
        "\n",
        "\n",
        "            listfordf.append(speech_mental_verbs_second_person)\n",
        "            procent = round(speech_mental_verbs_second_person/all_words*1000000)\n",
        "            listfordf.append(procent)\n",
        "            listparameters.append('Глаголы говорения и ментальной сферы в 2 лице')\n",
        "            listparameters.append('Процент вхождений глаголов говорения и ментальной сферы в 2 лице')\n",
        "\n",
        "\n",
        "    #df = pd.DataFrame(zip(listparameters, listdialogs, listauthor_speech, listfirstface), columns=columns)\n",
        "    df = pd.DataFrame(zip(listparameters, listdialogs, listauthor_speech), columns=columns)\n",
        "    \n",
        "    return df        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jh0tudnYUGda"
      },
      "source": [
        "def speech(dirname):\n",
        "\n",
        "    speech_verbs = ['говорить', 'сказать', 'называть', 'назвать', 'рассказывать',\n",
        "                    'рассказать', 'благодарить', 'отвечать', 'ответить', 'предложить',\n",
        "                    'предлагать', 'уверять', 'уверить', 'требовать', 'объявить',\n",
        "                    'просить', 'спрашивать', 'спросить', 'спорить', 'повторить',\n",
        "                    'повторять', 'обещать', 'возразить', 'признаться', 'признаваться',\n",
        "                    'жаловаться', 'пожаловаться', 'поблагодарить', 'обещать', 'советовать'] #30\n",
        "    mental_verbs = ['знать', 'думать', 'понимать', 'понять', 'помнить',\n",
        "                    'решить', 'подумать', 'мечтать', 'решать', 'забыть',\n",
        "                    'вспомнить', 'верить', 'надеяться', 'придумать', 'поверить',\n",
        "                    'задуматься', 'судить', 'сомневаться', 'напоминать', 'предполагать',\n",
        "                    'узнавать', 'узнать', 'определиться', 'определяться', 'полагать',\n",
        "                    'забывать', 'напомнить', 'предусмотреть', 'вздумать', 'выяснить'] #30\n",
        "\n",
        "\n",
        "    first_person = 0\n",
        "    impr = 0\n",
        "    speech_verbs_first_person = 0\n",
        "    mental_verbs_first_person = 0\n",
        "    speech_mental_verbs_second_person = 0\n",
        "\n",
        "    columns = ['показатели', 'прямая речь']\n",
        "    listparameters = []\n",
        "    listfordf = []\n",
        "\n",
        "    lemmas = []\n",
        "    textwords = []\n",
        "    forms_from_text = []\n",
        "    sentences = []\n",
        "\n",
        "    exclamations = 0\n",
        "    questions = 0\n",
        "\n",
        "    len_replicas = []\n",
        "\n",
        "    dir = os.listdir(dirname)\n",
        " \n",
        "    for i in tqdm(dir):\n",
        "        if i.endswith('.xml'):\n",
        "            filename = dirname + '/' + i\n",
        "\n",
        "            with open(filename, 'r', encoding = 'utf-8') as t:\n",
        "                xml_file = t.read()\n",
        "                soup = BeautifulSoup(xml_file, 'lxml')\n",
        "\n",
        "                frases = []\n",
        "\n",
        "                for string in soup.find_all('speech'):\n",
        "                    if soup.find('span', {'class': 'note'}) != None:\n",
        "                        frase = string.text.replace(soup.find('span', {'class': 'note'}).text, '')\n",
        "                    else:\n",
        "                        frase = string.text\n",
        "                    frases.append(frase.replace(' /', ''))\n",
        "                        \n",
        "                split_regex = re.compile(r'[\\.|!|?|…]')\n",
        "                replicas = []\n",
        "                for f in frases:\n",
        "                    replicas.extend([t.strip() for t in split_regex.split(f)])\n",
        "                for replica in replicas:\n",
        "                    if replica != '':\n",
        "                        sentences.append(replica)\n",
        "\n",
        "                \n",
        "                for f in frases:            \n",
        "                    exclamations += len(re.findall('!', f))\n",
        "                    questions += len(re.findall('\\?', f))\n",
        "\n",
        "                \n",
        "                for replica in replicas:\n",
        "                    if replica != '':\n",
        "                        tokens = word_tokenize(replica.lower())\n",
        "                        words = [w for w in tokens if w.isalpha()]\n",
        "                        textwords.extend(words)\n",
        "                        len_replicas.append(len(words))\n",
        "                \n",
        "\n",
        "    word_counter = Counter(textwords)\n",
        "    all_words = len(textwords)\n",
        "    listfordf.append(all_words)\n",
        "    listparameters.append('Всего слов')\n",
        "\n",
        "    listparameters.append('Восклицательные предложения')\n",
        "    listfordf.append(exclamations)\n",
        "    listparameters.append('Процент восклицательных предложений')\n",
        "    listfordf.append(round(exclamations*100/len(sentences)))\n",
        "\n",
        "    listparameters.append('Вопросительные предложения')\n",
        "    listfordf.append(questions)\n",
        "    listparameters.append('Процент вопросительных предложений')\n",
        "    listfordf.append(round(questions*100/len(sentences)))\n",
        "\n",
        "    listparameters.append('Средняя длина предложения')\n",
        "    listfordf.append(mean(len_replicas))\n",
        "\n",
        "    df_words = ['ну', 'а', \n",
        "                'вот', 'значит',\n",
        "                'да', 'нет',\n",
        "                'здесь', 'сегодня', 'сейчас',\n",
        "                'тут', 'там', 'тогда', 'такой', 'так',\n",
        "                'я']\n",
        "\n",
        "    for word in df_words:\n",
        "        count = word_counter[word]\n",
        "        listfordf.append(count)\n",
        "        procent = round(count/all_words*1000000)\n",
        "        listfordf.append(procent)\n",
        "\n",
        "        listparameters.append(word)\n",
        "        listparameters.append('Процент вхождений \\\"{}\\\"'.format(word))\n",
        "\n",
        "    for i in tqdm(textwords):\n",
        "        analise = morph.parse(i)\n",
        "        lemmas.append(analise)\n",
        "                                    \n",
        "    for lemma in lemmas:\n",
        "        if lemma[0].tag.POS == 'VERB':\n",
        "            if re.search('1per', str(lemma[0].tag)):\n",
        "                first_person += 1\n",
        "                for verb in speech_verbs:\n",
        "                    regexp = '^' + verb + '$'\n",
        "                    if re.search(regexp, lemma[0].normal_form) is not None:\n",
        "                        speech_verbs_first_person += 1\n",
        "                for verb in mental_verbs:\n",
        "                    regexp = '^' + verb + '$'\n",
        "                    if re.search(regexp, lemma[0].normal_form) is not None:\n",
        "                        mental_verbs_first_person += 1\n",
        "            if re.search('2per', str(lemma[0].tag)):\n",
        "                for verb in speech_verbs:\n",
        "                    regexp = '^' + verb + '$'\n",
        "                    if re.search(regexp, lemma[0].normal_form) is not None:\n",
        "                        speech_mental_verbs_second_person += 1\n",
        "                for verb in mental_verbs:\n",
        "                    regexp = '^' + verb + '$'\n",
        "                    if re.search(regexp, lemma[0].normal_form) is not None:\n",
        "                        speech_mental_verbs_second_person += 1\n",
        "            if re.search('impr', str(lemma[0].tag)):\n",
        "                impr += 1\n",
        "                        \n",
        "\n",
        "    listfordf.append(first_person)\n",
        "    procent = round(first_person/all_words*1000000)\n",
        "    listfordf.append(procent)\n",
        "    listparameters.append('Глаголы 1 лица')\n",
        "    listparameters.append('Процент вхождений глаголов 1 лица')\n",
        "\n",
        "    listfordf.append(impr)\n",
        "    procent = round(impr/all_words*1000000)\n",
        "    listfordf.append(procent)\n",
        "    listparameters.append('Глаголы impr')\n",
        "    listparameters.append('Процент вхождений глаголов impr')\n",
        "\n",
        "    listfordf.append(speech_verbs_first_person)\n",
        "    procent = round(speech_verbs_first_person/all_words*1000000)\n",
        "    listfordf.append(procent)\n",
        "    listparameters.append('Глаголы говорения в 1 лице')\n",
        "    listparameters.append('Процент вхождений глаголов говорения в 1 лице')\n",
        "\n",
        "    listfordf.append(mental_verbs_first_person)\n",
        "    procent = round(mental_verbs_first_person/all_words*1000000)\n",
        "    listfordf.append(procent)\n",
        "    listparameters.append('Глаголы ментальной сферы в 1 лице')\n",
        "    listparameters.append('Процент вхождений глаголов ментальной сферы в 1 лице')\n",
        "\n",
        "\n",
        "    listfordf.append(speech_mental_verbs_second_person)\n",
        "    procent = round(speech_mental_verbs_second_person/all_words*1000000)\n",
        "    listfordf.append(procent)\n",
        "    listparameters.append('Глаголы говорения и ментальной сферы в 2 лице')\n",
        "    listparameters.append('Процент вхождений глаголов говорения и ментальной сферы в 2 лице')\n",
        "\n",
        "\n",
        "    df = pd.DataFrame(zip(listparameters, listfordf), columns=columns)\n",
        "    \n",
        "    return df, lemmas, textwords, sentences, len(sentences)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}